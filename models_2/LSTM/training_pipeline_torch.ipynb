{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:48.653250766Z",
     "start_time": "2025-06-24T11:39:43.664089698Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:48.682647295Z",
     "start_time": "2025-06-24T11:39:48.666621228Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch implementation of a Long Short-Term Memory (LSTM) model for time-series forecasting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 output_size,\n",
    "                 dropout=0):\n",
    "\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Encoder: Compresses the input sequence\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Decoder: Reconstructs the sequence from the encoded representation\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_size,  # Input is the encoded representation\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Encode: Get the final hidden state as the compressed representation\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "\n",
    "        # Prepare decoder input: repeat the encoded representation for each timestep\n",
    "        # Use the last hidden state as the encoded representation\n",
    "        encoded = hidden[-1].unsqueeze(1).repeat(1, seq_len, 1)  # Shape: (batch, seq_len, hidden_size)\n",
    "\n",
    "        # Decode: Reconstruct the sequence\n",
    "        decoder_output, _ = self.decoder(encoded)\n",
    "\n",
    "        # Map back to original feature space\n",
    "        reconstructed = self.output_layer(decoder_output)\n",
    "\n",
    "        return reconstructed\n",
    "\n",
    "    def get_reconstruction_error(self, x):\n",
    "        \"\"\"Calculate reconstruction error for anomaly detection\"\"\"\n",
    "        #TODO if its near port be more forgiving \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.forward(x)\n",
    "            # Calculate MSE for each sequence\n",
    "            mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))\n",
    "            return mse.gpu().numpy() #NOTE cpu\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Get the encoded representation of input sequences\"\"\"\n",
    "        with torch.no_grad():\n",
    "            _, (hidden, _) = self.encoder(x)\n",
    "            return hidden[-1]  # Return the last layer's hidden state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:48.734835514Z",
     "start_time": "2025-06-24T11:39:48.678420539Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Creates sequences from time-series data for training recurrent neural networks.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): The input time-series data.\n",
    "        seq_length (int): The length of each input sequence.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two numpy arrays:\n",
    "               - xs (np.array): Input sequences.\n",
    "               - ys (np.array): Target values (the next step after the sequence).\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i : i + seq_length])\n",
    "        ys.append(data[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:48.776357487Z",
     "start_time": "2025-06-24T11:39:48.703233686Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def divide_validation(X, y):\n",
    "    X_train, y_train, X_val, y_val = [], [], [], []\n",
    "    # Split the data into training and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:57.563815810Z",
     "start_time": "2025-06-24T11:39:57.546997507Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for experiment: lstm_per_route_v1\n",
      "Training epochs: 10, Batch size: 16\n",
      "Output directories: models_per_route_lstm_ae\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - MODIFY THESE TO EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "# Data parameters\n",
    "DATA_PATH = \"LSTM_preprocessed.parquet\"\n",
    "EXPERIMENT_NAME = \"lstm_per_route_v1\"\n",
    "\n",
    "# Feature columns to use (must match data preprocessing)\n",
    "# FEATURE_COLUMNS = [\n",
    "#     \"speed_over_ground\", \"dv\", \"dcourse\", \"ddraft\",\n",
    "#     \"zone\", \"x_km\", \"y_km\", \"dist_to_ref\", \"route_dummy\"\n",
    "# ]\n",
    "\n",
    "FEATURE_COLUMNS = ['latitude', 'longitude',\n",
    "                   'speed_over_ground', 'course_over_ground',\n",
    "                   'zone']\n",
    "\n",
    "\n",
    "# Sequence parameters\n",
    "SEQUENCE_LENGTH = 10        # Number of time steps in each sequence\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 10                 # Maximum epochs (early stopping will likely kick in)\n",
    "BATCH_SIZE = 16             # Training batch size\n",
    "PATIENCE = 5               # Early stopping patience\n",
    "VALIDATION_SIZE = 0.2       # Proportion of data for validation\n",
    "\n",
    "# Evaluation parameters\n",
    "AUTOENCODER_THRESHOLD_PERCENTILE = 95  # Threshold for autoencoder (95th percentile)\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR_AE = \"models_per_route_lstm_ae\"    # Autoencoder models\n",
    "\n",
    "print(f\"Configuration loaded for experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Training epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Output directories: {OUTPUT_DIR_AE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:58.042857246Z",
     "start_time": "2025-06-24T11:39:58.017512433Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=len(FEATURE_COLUMNS), hidden_size=128, num_layers=1, output_size=len(FEATURE_COLUMNS))\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:59.586788504Z",
     "start_time": "2025-06-24T11:39:58.420677861Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trips: 420\n",
      "Normal trips: 356\n",
      "Anomaly trips: 62\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_PATH)\n",
    "df.sort_values(['trip_id', 'time_stamp'], inplace=True)\n",
    "\n",
    "df_KIEL = df[df['start_port'] == 'KIEL'].copy()\n",
    "\n",
    "def divide_normal_anomaly(df):\n",
    "    normal_trip_ids = df.groupby('trip_id')['y_true'].all()\n",
    "    normal_trip_ids = normal_trip_ids[normal_trip_ids == True].index\n",
    "    df_completely_normal_trips = df[df['trip_id'].isin(normal_trip_ids)].copy()\n",
    "\n",
    "    anomaly_trip_ids = df.groupby('trip_id')['y_true'].any()\n",
    "    anomaly_trip_ids = anomaly_trip_ids[anomaly_trip_ids == True].index\n",
    "    df_trips_with_anomalies = df[df['trip_id'].isin(anomaly_trip_ids)].copy()\n",
    "\n",
    "    return df_completely_normal_trips, df_trips_with_anomalies\n",
    "\n",
    "df_normal, df_anomalies = divide_normal_anomaly(df_KIEL)\n",
    "\n",
    "print(f\"Total trips: {len(df_KIEL['trip_id'].unique())}\")\n",
    "print(f\"Normal trips: {len(df_normal['trip_id'].unique())}\")\n",
    "print(f\"Anomaly trips: {len(df_anomalies['trip_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:39:59.644334558Z",
     "start_time": "2025-06-24T11:39:59.577331663Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = df_normal[FEATURE_COLUMNS].values\n",
    "training_data_scaled = scaler.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:40:01.862216420Z",
     "start_time": "2025-06-24T11:40:00.306157084Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = create_sequences(training_data_scaled, SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:40:03.930962188Z",
     "start_time": "2025-06-24T11:40:01.867910607Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Move model and loss function to CUDA\n",
    "model = model.to(device)\n",
    "loss_function = loss_function.to(device)\n",
    "\n",
    "# Create tensors directly on CUDA\n",
    "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "# Create dataset and dataloader (tensors are already on CUDA)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-24T11:40:03.937489125Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LSTM: 100%|██████████| 10/10 [19:39<00:00, 117.96s/it, epoch=10/10, batch=28362/28362, loss=0.000568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epoch_pbar = tqdm(range(EPOCHS), desc=\"Training LSTM\")\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    train_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch_x, _ in train_loader:\n",
    "        reconstructed = model(batch_x)\n",
    "        loss = loss_function(reconstructed, batch_x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        train_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Update progress bar every 100 batches to show batch progress\n",
    "        if batch_count % 100 == 0:\n",
    "            current_avg_loss = train_loss / batch_count\n",
    "            epoch_pbar.set_postfix({\n",
    "                'epoch': f'{epoch+1}/{EPOCHS}',\n",
    "                'batch': f'{batch_count}/{len(train_loader)}',\n",
    "                'loss': f'{current_avg_loss:.6f}'\n",
    "            })\n",
    "    \n",
    "    # Calculate final average loss for the epoch\n",
    "    avg_loss = train_loss / batch_count\n",
    "    epoch_pbar.set_postfix({\n",
    "        'epoch': f'{epoch+1}/{EPOCHS}',\n",
    "        'batch': f'{batch_count}/{len(train_loader)}',\n",
    "        'loss': f'{avg_loss:.6f}'\n",
    "    })\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_port</th>\n",
       "      <th>end_port</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>...</th>\n",
       "      <th>dv</th>\n",
       "      <th>dcourse</th>\n",
       "      <th>ddraft</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone_0</th>\n",
       "      <th>zone_1</th>\n",
       "      <th>x_km</th>\n",
       "      <th>y_km</th>\n",
       "      <th>dist_to_ref</th>\n",
       "      <th>route_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-263.743269</td>\n",
       "      <td>-31.487677</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-04 08:02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-263.743269</td>\n",
       "      <td>-31.487677</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-04 08:03:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-263.743269</td>\n",
       "      <td>-31.487677</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-04 08:04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-263.743269</td>\n",
       "      <td>-31.487677</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-04 08:05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-263.743269</td>\n",
       "      <td>-31.487677</td>\n",
       "      <td>0.169412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-06 02:33:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>301.817486</td>\n",
       "      <td>0.578783</td>\n",
       "      <td>25.398605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-06 02:34:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>301.817486</td>\n",
       "      <td>0.578783</td>\n",
       "      <td>25.398605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-06 02:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>301.817486</td>\n",
       "      <td>0.578783</td>\n",
       "      <td>25.398605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-06 02:36:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>301.817486</td>\n",
       "      <td>-0.526957</td>\n",
       "      <td>29.041675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>19585</td>\n",
       "      <td>54.36</td>\n",
       "      <td>10.14</td>\n",
       "      <td>2016-07-04 08:01:00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>18.92</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>KIEL</td>\n",
       "      <td>GDYNIA</td>\n",
       "      <td>2016-07-06 02:37:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>301.817486</td>\n",
       "      <td>-0.526957</td>\n",
       "      <td>29.041675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trip_id  start_latitude  start_longitude          start_time  \\\n",
       "1237    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "1238    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "1239    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "1240    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "1241    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "...       ...             ...              ...                 ...   \n",
       "2878    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "2879    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "2880    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "2881    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "2882    19585           54.36            10.14 2016-07-04 08:01:00   \n",
       "\n",
       "      end_latitude  end_longitude            end_time start_port end_port  \\\n",
       "1237         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "1238         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "1239         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "1240         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "1241         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "...            ...            ...                 ...        ...      ...   \n",
       "2878         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "2879         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "2880         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "2881         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "2882         54.64          18.92 2016-07-06 02:37:00       KIEL   GDYNIA   \n",
       "\n",
       "              time_stamp  ...   dv  dcourse  ddraft  zone  zone_0  zone_1  \\\n",
       "1237 2016-07-04 08:01:00  ...  0.0      0.0     0.0     1   False    True   \n",
       "1238 2016-07-04 08:02:00  ...  1.1      5.2     0.0     1   False    True   \n",
       "1239 2016-07-04 08:03:00  ...  0.9      0.5     0.0     1   False    True   \n",
       "1240 2016-07-04 08:04:00  ...  0.9      3.9     0.0     1   False    True   \n",
       "1241 2016-07-04 08:05:00  ...  1.0      1.4     0.0     1   False    True   \n",
       "...                  ...  ...  ...      ...     ...   ...     ...     ...   \n",
       "2878 2016-07-06 02:33:00  ...  0.0      0.8     0.0     1   False    True   \n",
       "2879 2016-07-06 02:34:00  ...  0.1      0.5     0.0     1   False    True   \n",
       "2880 2016-07-06 02:35:00  ...  0.1      0.3     0.0     1   False    True   \n",
       "2881 2016-07-06 02:36:00  ...  0.0      0.0     0.0     1   False    True   \n",
       "2882 2016-07-06 02:37:00  ...  0.0      0.2     0.0     1   False    True   \n",
       "\n",
       "            x_km       y_km  dist_to_ref route_dummy  \n",
       "1237 -263.743269 -31.487677     0.169412         1.0  \n",
       "1238 -263.743269 -31.487677     0.169412         1.0  \n",
       "1239 -263.743269 -31.487677     0.169412         1.0  \n",
       "1240 -263.743269 -31.487677     0.169412         1.0  \n",
       "1241 -263.743269 -31.487677     0.169412         1.0  \n",
       "...          ...        ...          ...         ...  \n",
       "2878  301.817486   0.578783    25.398605         1.0  \n",
       "2879  301.817486   0.578783    25.398605         1.0  \n",
       "2880  301.817486   0.578783    25.398605         1.0  \n",
       "2881  301.817486  -0.526957    29.041675         1.0  \n",
       "2882  301.817486  -0.526957    29.041675         1.0  \n",
       "\n",
       "[1646 rows x 33 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_anomaly = df_anomalies[df_anomalies['trip_id'] == df_anomalies['trip_id'].unique()[0]]\n",
    "one_anomaly = one_anomaly.sort_values('time_stamp')\n",
    "one_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_anomaly['lstm_prediction'] = 0\n",
    "\n",
    "# Get reconstruction errors for the anomaly trip\n",
    "anomaly_tr_features = one_anomaly[FEATURE_COLUMNS].values\n",
    "anomaly_tr_features_scaled = scaler.transform(anomaly_tr_features)  # Use transform, not fit_transform\n",
    "\n",
    "X_anomaly, y_anomaly = create_sequences(anomaly_tr_features_scaled, SEQUENCE_LENGTH)\n",
    "X_anomaly_tensor = torch.from_numpy(X_anomaly).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model.forward(X_anomaly_tensor)\n",
    "    # Calculate MSE for each sequence\n",
    "    mse = torch.mean((X_anomaly_tensor - reconstructed) ** 2, dim=(1, 2))\n",
    "    reconstruction_errors = mse.cpu().numpy()\n",
    "\n",
    "# Calculate threshold (you should ideally calculate this from training data)\n",
    "threshold = np.percentile(reconstruction_errors, AUTOENCODER_THRESHOLD_PERCENTILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_mask = reconstruction_errors > threshold\n",
    "anomaly_indices = np.where(anomaly_mask)[0]\n",
    "\n",
    "# Mark points as anomalous based on which sequences they belong to\n",
    "for seq_idx in anomaly_indices:\n",
    "    start_point = seq_idx\n",
    "    end_point = min(seq_idx + SEQUENCE_LENGTH, len(one_anomaly))\n",
    "    \n",
    "    # Mark all points in this sequence as anomalous\n",
    "    one_anomaly.iloc[start_point:end_point, one_anomaly.columns.get_loc('lstm_prediction')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Predictions Summary:\n",
      "Total points: 1646\n",
      "LSTM predicted anomalies: 185\n",
      "Ground truth anomalies: 22\n",
      "True positives 0\n",
      "False positives 185\n",
      "False Negatives 22\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM Predictions Summary:\")\n",
    "print(f\"Total points: {len(one_anomaly)}\")\n",
    "print(f\"LSTM predicted anomalies: {(one_anomaly['lstm_prediction'] == 1).sum()}\")\n",
    "print(f\"Ground truth anomalies: {(one_anomaly['y_true'] == 1).sum()}\")\n",
    "\n",
    "# Calculate some basic metrics\n",
    "true_positives = ((one_anomaly['y_true'] == 1) & (one_anomaly['lstm_prediction'] == 1)).sum()\n",
    "false_positives = ((one_anomaly['y_true'] == 0) & (one_anomaly['lstm_prediction'] == 1)).sum()\n",
    "false_negatives = ((one_anomaly['y_true'] == 1) & (one_anomaly['lstm_prediction'] == 0)).sum()\n",
    "\n",
    "\n",
    "print(f\"True positives {true_positives}\") \n",
    "print(f\"False positives {false_positives}\") \n",
    "print(f\"False Negatives {false_negatives}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 229.37 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     reconstructed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     mse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((X_train_tensor \u001b[38;5;241m-\u001b[39m reconstructed) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     12\u001b[0m     train_reconstruction_errors \u001b[38;5;241m=\u001b[39m mse\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[60], line 51\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m batch_size, seq_len, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Encode: Get the final hidden state as the compressed representation\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m _, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Prepare decoder input: repeat the encoded representation for each timestep\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Use the last hidden state as the encoded representation\u001b[39;00m\n\u001b[1;32m     55\u001b[0m encoded \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, seq_len, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch, seq_len, hidden_size)\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/appl/software/PyTorch/2.3.0-foss-2023b-CUDA-12.4.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/appl/software/PyTorch/2.3.0-foss-2023b-CUDA-12.4.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/appl/software/PyTorch/2.3.0-foss-2023b-CUDA-12.4.0/lib/python3.11/site-packages/torch/nn/modules/rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 229.37 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# Add this to your training notebook after training is complete\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Calculate threshold on training data (you should do this properly)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model.forward(X_train_tensor)\n",
    "    mse = torch.mean((X_train_tensor - reconstructed) ** 2, dim=(1, 2))\n",
    "    train_reconstruction_errors = mse.cpu().numpy()\n",
    "\n",
    "threshold = np.percentile(train_reconstruction_errors, AUTOENCODER_THRESHOLD_PERCENTILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (encoder): LSTM(5, 128, batch_first=True)\n",
       "  (decoder): LSTM(128, 128, batch_first=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything needed for inference\n",
    "lstm_artifacts = {\n",
    "    \"model_state\": model.state_dict(),  # PyTorch model state\n",
    "    \"scaler\": scaler,  # MinMaxScaler fitted on training data\n",
    "    \"threshold\": threshold,  # Anomaly threshold\n",
    "    \"model_config\": {\n",
    "        \"input_size\": len(FEATURE_COLUMNS),\n",
    "        \"hidden_size\": 128,  # From your model definition\n",
    "        \"num_layers\": 1,     # From your model definition\n",
    "        \"sequence_length\": SEQUENCE_LENGTH,\n",
    "        \"threshold_percentile\": AUTOENCODER_THRESHOLD_PERCENTILE\n",
    "    },\n",
    "    \"features\": FEATURE_COLUMNS,  # Feature names for compatibility\n",
    "    \"model_type\": \"lstm\"  # Identifier for the visualizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model saved to models_per_route_lstm_ae/KIEL_lstm_model.pkl\n",
      "Dispatcher saved to models_per_route_lstm_ae/dispatcher.pkl\n",
      "To use with visualizer, run:\n",
      "python data_visualizer.py <trip_id> --dispatcher models_per_route_lstm_ae/dispatcher.pkl --model-type lstm\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "output_dir = Path(\"models_per_route_lstm_ae\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save for the specific route (KIEL in your case)\n",
    "route_name = \"KIEL\"  # or get it from your data\n",
    "model_filename = output_dir / f\"{route_name}_lstm_model.pkl\"\n",
    "joblib.dump(lstm_artifacts, model_filename)\n",
    "\n",
    "print(f\"LSTM model saved to {model_filename}\")\n",
    "\n",
    "# Create dispatcher file for LSTM models\n",
    "dispatcher_lstm = {\n",
    "    route_name: str(model_filename)\n",
    "}\n",
    "\n",
    "dispatcher_file = output_dir / \"dispatcher.pkl\"\n",
    "joblib.dump(dispatcher_lstm, dispatcher_file)\n",
    "print(f\"Dispatcher saved to {dispatcher_file}\")\n",
    "\n",
    "print(\"To use with visualizer, run:\")\n",
    "print(f\"python data_visualizer.py <trip_id> --dispatcher {dispatcher_file} --model-type lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

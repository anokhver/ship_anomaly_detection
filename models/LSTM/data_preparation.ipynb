{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.474183249Z",
     "start_time": "2025-06-18T16:01:21.150143429Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**New added features:**\n",
    "- dv --- Delta speed over ground\n",
    "- dcourse --- Delta course over ground (degrees)\n",
    "- ddraft --- Delta draught\n",
    "- zone ---          ?\n",
    "- x_km --- Local x coordinate in km (relative to route center)\n",
    "- y_km --- Local y coordinate in km (relative to route center)\n",
    "- dist_to_ref --- Distance to average route trajectory (km)\n",
    "- route_dummy --- ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "DROP_TRIPS = [10257]\n",
    "\n",
    "ZONES = [[53.8, 53.5, 8.6, 8.14], [53.66, 53.0, 11.0, 9.5]]\n",
    "\n",
    "# Distance thresholds for port proximity analysis\n",
    "R_PORT, R_APP = 5.0, 15.0       # Port radius and approach radius in km\n",
    "EARTH_R = 6_371.0              # Earth radius in km for distance calculations\n",
    "RANDOM_STATE = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.515505987Z",
     "start_time": "2025-06-18T16:01:21.514550887Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "───────────────────────────── Helper Functions ──────────────────────────────"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate great-circle distance between points using Haversine formula.\n",
    "\n",
    "    This is essential for maritime data as vessels travel on Earth's curved surface.\n",
    "    Used for computing distances between GPS coordinates and measuring trajectory\n",
    "    deviations from reference routes.\n",
    "\n",
    "    Args:\n",
    "        lat1, lon1: Latitude and longitude of first point(s) in degrees\n",
    "        lat2, lon2: Latitude and longitude of second point(s) in degrees\n",
    "\n",
    "    Returns:\n",
    "        Distance in kilometers (vectorized for arrays)\n",
    "    \"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, (lat1, lon1, lat2, lon2))\n",
    "\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_R * np.arcsin(np.sqrt(a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.515748585Z",
     "start_time": "2025-06-18T16:01:21.514765280Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_and_prepare(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and perform initial data preparation.\n",
    "\n",
    "    This function handles the core preprocessing steps:\n",
    "    1. Data loading and cleaning (removing problematic trips)\n",
    "    2. Date parsing for temporal analysis\n",
    "    3. Delta feature computation for detecting sudden changes\n",
    "    4. Zone classification\n",
    "\n",
    "    Delta features are crucial for anomaly detection as they capture:\n",
    "    - Sudden speed changes (acceleration/deceleration anomalies)\n",
    "    - Course changes (navigation anomalies)\n",
    "    - Draft changes (loading/unloading anomalies)\n",
    "\n",
    "    Args:\n",
    "        path: Path to the parquet file containing vessel trajectory data\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed DataFrame with delta features and zone classifications\n",
    "    \"\"\"\n",
    "\n",
    "    #--- Step 1: Load data and remove problematic trips\n",
    "    df = pd.read_parquet(path, engine=\"pyarrow\")\n",
    "    print(f\"Loaded {len(df):,} rows, dropping {len(df[df.trip_id.isin(DROP_TRIPS)]):,} rows from {DROP_TRIPS}\")\n",
    "    df = df[~df.trip_id.isin(DROP_TRIPS)].reset_index(drop=True)\n",
    "\n",
    "    #--- Step 2: Parse datetime columns for temporal analysis\n",
    "    for col in (\"start_time\", \"end_time\", \"time_stamp\"):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    # Create binary anomaly labels for supervised learning\n",
    "    df[\"y_true\"] = df[\"is_anomaly\"].map({True: 1, False: 0})\n",
    "    df[\"route_id\"] = df[\"start_port\"] # Route identifier for route-specific processing\n",
    "\n",
    "    # Compute delta features (changes between consecutive points)\n",
    "    # These capture sudden behavioral changes that may indicate anomalies\n",
    "    df = df.sort_values([\"trip_id\", \"time_stamp\"])\n",
    "    df[\"dv\"] = df.groupby(\"trip_id\")[\"speed_over_ground\"].diff().abs().fillna(0)\n",
    "    df[\"dcourse\"] = df.groupby(\"trip_id\")[\"course_over_ground\"].diff().abs().fillna(0)\n",
    "    df[\"ddraft\"] = df.groupby(\"trip_id\")[\"draught\"].diff().abs().fillna(0)\n",
    "\n",
    "    def _in_any_rect(lat: float, lon: float) -> bool:\n",
    "        \"\"\"Check if coordinates are within any defined port zone.\"\"\"\n",
    "        for lat_max, lat_min, lon_max, lon_min in ZONES:\n",
    "            if lat_min <= lat <= lat_max and lon_min <= lon <= lon_max:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def zone_label(row) -> int:\n",
    "        \"\"\"\n",
    "        Classify vessel position as port area (0) or open water (1).\n",
    "\n",
    "        This spatial context is important because:\n",
    "        - Port areas have different traffic patterns and regulations\n",
    "        - Anomalous behavior may be normal in ports but suspicious in open water\n",
    "        - LSTM can learn different behavioral patterns for different zones\n",
    "        \"\"\"\n",
    "        if _in_any_rect(row.latitude, row.longitude):\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    # Apply zone classification with progress tracking\n",
    "    df[\"zone\"] = df.progress_apply(zone_label, axis=1)\n",
    "    # Create one-hot encoded zone features for the model\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"zone\"], prefix=\"zone\")], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.515831937Z",
     "start_time": "2025-06-18T16:01:21.514888791Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "───────────────────────────── Route Features ──────────────────────────────"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def compute_average_route(df_route: pd.DataFrame, n_points: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute average trajectory for a specific route.\n",
    "\n",
    "    This creates a reference trajectory by:\n",
    "    1. Resampling each trip to a fixed number of points along the route\n",
    "    2. Normalizing by cumulative distance fraction (0 to 1)\n",
    "    3. Averaging corresponding points across all trips\n",
    "\n",
    "    The reference trajectory is essential for measuring deviations:\n",
    "    - Normal trips should follow the average route closely\n",
    "    - Anomalous trips may deviate significantly from the reference\n",
    "\n",
    "    Args:\n",
    "        df_route: DataFrame containing all trips for a specific route\n",
    "        n_points: Number of points to use for the reference trajectory\n",
    "\n",
    "    Returns:\n",
    "        Array of shape (n_points, 2) containing [lat, lon] of reference trajectory\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    for _, trip in df_route.groupby(\"trip_id\"):\n",
    "        trip = trip.sort_values(\"time_stamp\")\n",
    "        lat, lon = trip.latitude.to_numpy(), trip.longitude.to_numpy()\n",
    "\n",
    "        # Calculate cumulative distance along the trip\n",
    "        d = haversine(lat[1:], lon[1:], lat[:-1], lon[:-1])\n",
    "        cum = np.concatenate(([0], np.cumsum(d)))\n",
    "\n",
    "        if cum[-1] <= 0:  # Skip trips with no movement\n",
    "            continue\n",
    "\n",
    "        # Normalize to fraction of total trip distance\n",
    "        frac = cum / cum[-1]\n",
    "\n",
    "        # Resample to fixed number of points\n",
    "        target = np.linspace(0, 1, n_points)\n",
    "        segments.append(np.vstack([np.interp(target, frac, lat),\n",
    "                                   np.interp(target, frac, lon)]).T)\n",
    "    if not segments:\n",
    "        return np.array([])\n",
    "\n",
    "    # Average corresponding points across all trips\n",
    "    return np.mean(np.stack(segments, axis=0), axis=0)\n",
    "\n",
    "def add_route_specific_features(df: pd.DataFrame, route: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add route-specific features for improved anomaly detection.\n",
    "\n",
    "    This function creates:\n",
    "    1. Local coordinate projection (x_km, y_km) for distance calculations\n",
    "    2. Distance to reference trajectory for measuring route deviations\n",
    "\n",
    "    Route-specific features are important because:\n",
    "    - Different routes have different normal patterns\n",
    "    - Local coordinates make distance calculations more accurate\n",
    "    - Deviation from reference trajectory is a strong anomaly indicator\n",
    "\n",
    "    Args:\n",
    "        df: Full DataFrame with all routes\n",
    "        route: Specific route to process\n",
    "\n",
    "    Returns:\n",
    "        DataFrame subset with route-specific features added\n",
    "    \"\"\"\n",
    "\n",
    "    df_r = df[df.route_id == route].copy()\n",
    "\n",
    "    # Create local coordinate system centered on route's geographic center\n",
    "    # This improves distance calculation accuracy over large areas\n",
    "    lat0, lon0 = df_r.latitude.mean(), df_r.longitude.mean()\n",
    "    kx = 111.320 * np.cos(np.deg2rad(lat0))     # Longitude to km (varies with latitude)\n",
    "    ky = 110.574                                # Latitude to km (roughly constant)\n",
    "    df_r[\"x_km\"] = (df_r.longitude - lon0) * kx\n",
    "    df_r[\"y_km\"] = (df_r.latitude - lat0) * ky\n",
    "\n",
    "    # Compute reference trajectory and distance deviations\n",
    "    avg = compute_average_route(df_r)\n",
    "    if avg.size == 0: # Handle routes with insufficient data\n",
    "        df_r[\"dist_to_ref\"] = 0.0\n",
    "        df_r[\"route_dummy\"] = 1.0\n",
    "        return df_r\n",
    "\n",
    "    # Calculate distance to reference trajectory for each point\n",
    "    idx_map = df_r.index\n",
    "    frac = np.zeros(len(df_r)) # Fraction along route for each point\n",
    "\n",
    "    for _, trip in tqdm(df_r.groupby(\"trip_id\"), desc=f\"Processing trips for route {route}\"):\n",
    "        pos = idx_map.get_indexer(trip.index)\n",
    "        lat, lon = trip.latitude.values, trip.longitude.values\n",
    "        d = haversine(lat[1:], lon[1:], lat[:-1], lon[:-1])\n",
    "\n",
    "        # Calculate cumulative distance along this trip\n",
    "        cum = np.concatenate(([0], np.cumsum(d)))\n",
    "        total = cum[-1] if cum[-1] > 0 else 1\n",
    "        frac[pos] = cum / total\n",
    "\n",
    "    # Compute distance from each point to corresponding reference point\n",
    "    df_r[\"dist_to_ref\"] = [\n",
    "        haversine(lat, lon, avg[int(f * 99), 0], avg[int(f * 99), 1])\n",
    "        for lat, lon, f in zip(df_r.latitude, df_r.longitude, frac)\n",
    "    ]\n",
    "    df_r[\"route_dummy\"] = 1.0\n",
    "    return df_r"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.522026819Z",
     "start_time": "2025-06-18T16:01:21.515003742Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "───────────────────────────── Main Preprocessing ──────────────────────────────"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_prepared_dfs(data_path: str):\n",
    "    \"\"\"\n",
    "    Process all routes and return list of prepared DataFrames.\n",
    "\n",
    "    This function applies route-specific processing to each route separately,\n",
    "    which is important because different routes have different:\n",
    "    - Geographic characteristics\n",
    "    - Traffic patterns\n",
    "    - Normal operational behaviors\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to input data file\n",
    "\n",
    "    Returns:\n",
    "        List of DataFrames, one per route, with all features computed\n",
    "    \"\"\"\n",
    "    df = load_and_prepare(data_path)\n",
    "\n",
    "    dfs = []\n",
    "    for route in df.route_id.unique():\n",
    "        fr = add_route_specific_features(df, route)\n",
    "        dfs.append(fr)\n",
    "\n",
    "    return dfs\n",
    "\n",
    "def preprocess_df(data_path: str, output_dir: str,\n",
    "                  name: str = \"LSTM_preprocessed\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for vessel trajectory data.\n",
    "\n",
    "    This is the main function that orchestrates the entire preprocessing:\n",
    "    1. Load and clean raw data\n",
    "    2. Compute delta features and zone classifications\n",
    "    3. Process each route separately for route-specific features\n",
    "    4. Combine all routes into final dataset\n",
    "    5. Save preprocessed data for model training\n",
    "\n",
    "    The resulting dataset is optimized for LSTM training with:\n",
    "    - Sequential temporal structure (sorted by trip and time)\n",
    "    - Engineered features capturing behavioral changes\n",
    "    - Spatial context through zone and distance features\n",
    "    - Route-specific normalization\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to input parquet file\n",
    "        output_dir: Directory to save processed data\n",
    "        name: Name for output file (without extension)\n",
    "\n",
    "    Returns:\n",
    "        Final preprocessed DataFrame ready for LSTM training\n",
    "    \"\"\"\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    model_path = f\"{output_dir}/{name}.parquet\"\n",
    "\n",
    "    dfs = get_prepared_dfs(data_path)\n",
    "    df_final = pd.concat(dfs, ignore_index=True)\n",
    "    df_final.sort_values([\"trip_id\", \"time_stamp\"], inplace=True)\n",
    "\n",
    "    df_final.to_parquet(model_path, index=False)\n",
    "    print(f\"Saved processed data to {model_path}\")\n",
    "    return df_final"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:21.528346333Z",
     "start_time": "2025-06-18T16:01:21.525537731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 913,595 rows, dropping 577 rows from [10257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 913018/913018 [00:15<00:00, 60204.44it/s]\n",
      "Processing trips for route KIEL: 100%|██████████| 423/423 [00:00<00:00, 1434.89it/s]\n",
      "Processing trips for route BREMERHAVEN: 100%|██████████| 702/702 [00:00<00:00, 2313.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to data/LSTM_preprocessed.parquet\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/cleaned/connected_labeled_anomalies.parquet\"\n",
    "output_dir = \"data\"\n",
    "\n",
    "df_final = preprocess_df(data_path, output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T16:01:50.584302486Z",
     "start_time": "2025-06-18T16:01:21.530406316Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

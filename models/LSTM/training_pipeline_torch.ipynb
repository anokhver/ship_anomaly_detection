{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T14:28:31.976817740Z",
     "start_time": "2025-06-24T14:28:31.973136209Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMModel interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T14:28:32.454019811Z",
     "start_time": "2025-06-24T14:28:32.434327909Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch implementation of a Long Short-Term Memory (LSTM) model for time-series forecasting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 output_size,\n",
    "                 dropout=0):\n",
    "\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Encode: Get the final hidden state as the compressed representation\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "\n",
    "        # Prepare decoder input: repeat the encoded representation for each timestep\n",
    "        # Use the last hidden state as the encoded representation\n",
    "        encoded = hidden[-1].unsqueeze(1).repeat(1, seq_len, 1)  # Shape: (batch, seq_len, hidden_size)\n",
    "\n",
    "        # Decode: Reconstruct the sequence\n",
    "        decoder_output, _ = self.decoder(encoded)\n",
    "\n",
    "        # Map back to original feature space\n",
    "        reconstructed = self.output_layer(decoder_output)\n",
    "\n",
    "        return reconstructed\n",
    "\n",
    "    def get_reconstruction_error(self, x):\n",
    "        \"\"\"Calculate reconstruction error for anomaly detection\"\"\"\n",
    "        with torch.no_grad():\n",
    "            reconstructed = self.forward(x)\n",
    "            # Calculate MSE for each sequence\n",
    "            mse = torch.mean((x - reconstructed) ** 2, dim=(1, 2))\n",
    "            return mse.cpu().numpy()  # Changed from .gpu() to .cpu()\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Get the encoded representation of input sequences\"\"\"\n",
    "        with torch.no_grad():\n",
    "            _, (hidden, _) = self.encoder(x)\n",
    "            return hidden[-1]  # Return the last layer's hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for experiment: lstm_per_route_v1\n",
      "Training epochs: 10, Batch size: 16\n",
      "Output directories: models_per_route_lstm_ae\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - MODIFY THESE TO EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "# Data parameters\n",
    "DATA_PATH = \"LSTM_preprocessed.parquet\"\n",
    "EXPERIMENT_NAME = \"lstm_per_route_v1\"\n",
    "\n",
    "# FEATURE_COLUMNS = ['latitude', 'longitude',\n",
    "#                    'speed_over_ground', 'course_over_ground'\n",
    "#                    ]\n",
    "\n",
    "FEATURE_COLUMNS = [ \"speed_over_ground\", \"course_over_ground\",\n",
    "                    \"x_km\", \"y_km\", \"dist_to_ref\", \"zone\"\n",
    "                  ]\n",
    "\n",
    "# Sequence parameters\n",
    "SEQUENCE_LENGTH = 15        # Number of time steps in each sequence\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 10                 # Maximum epochs\n",
    "BATCH_SIZE = 16            \n",
    "PATIENCE = 5                # Early stopping patience\n",
    "VALIDATION_SIZE = 0.2       # Proportion of data for validation\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 1 \n",
    "\n",
    "# Evaluation parameters\n",
    "AUTOENCODER_THRESHOLD_PERCENTILE = 95\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR_AE = \"models_per_route_lstm_ae\"    # Autoencoder models\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "print(f\"Configuration loaded for experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Training epochs: {EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Output directories: {OUTPUT_DIR_AE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T14:28:32.986938385Z",
     "start_time": "2025-06-24T14:28:32.969052825Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Creates sequences from time-series data for training recurrent neural networks.\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i : i + seq_length])\n",
    "        ys.append(data[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def divide_validation(X, y):\n",
    "    X_train, y_train, X_val, y_val = [], [], [], []\n",
    "    # Split the data into training and validation sets\n",
    "\n",
    "def divide_normal_anomaly(df):\n",
    "    normal_trip_ids = df.groupby('trip_id')['y_true'].all()\n",
    "    normal_trip_ids = normal_trip_ids[normal_trip_ids == True].index\n",
    "    df_completely_normal_trips = df[df['trip_id'].isin(normal_trip_ids)].copy()\n",
    "\n",
    "    anomaly_trip_ids = df.groupby('trip_id')['y_true'].any()\n",
    "    anomaly_trip_ids = anomaly_trip_ids[anomaly_trip_ids == True].index\n",
    "    df_trips_with_anomalies = df[df['trip_id'].isin(anomaly_trip_ids)].copy()\n",
    "\n",
    "\n",
    "    print(f\"Total trips: {len(df['trip_id'].unique())}\")\n",
    "    print(f\"Normal trips: {len(df_completely_normal_trips['trip_id'].unique())}\")\n",
    "    print(f\"Anomaly trips: {len(df_trips_with_anomalies['trip_id'].unique())}\")\n",
    "    \n",
    "    return df_completely_normal_trips, df_trips_with_anomalies\n",
    "    \n",
    "def get_data_loader(df):\n",
    "    data_features = df[FEATURE_COLUMNS].values\n",
    "    data_scaled = scaler.fit_transform(data_features)\n",
    "\n",
    "    X, y = create_sequences(data_scaled, SEQUENCE_LENGTH)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    y_tensor = torch.from_numpy(y).float()\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "def load_data_route(route, datapath = DATA_PATH):\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    df.sort_values(['trip_id', 'time_stamp'], inplace=True)\n",
    "    df_route = df[df['start_port'] == route].copy()\n",
    "\n",
    "    return df_route\n",
    "\n",
    "def get_anomaly_example(df_anomalies):\n",
    "    \n",
    "    one_anomaly = df_anomalies[df_anomalies['trip_id'] == df_anomalies['trip_id'].unique()[0]].copy()\n",
    "    one_anomaly['lstm_prediction'] = 0\n",
    "    \n",
    "    one_anomaly = one_anomaly.sort_values('time_stamp')\n",
    "    one_an_scaled = scaler.transform(one_anomaly[FEATURE_COLUMNS].values)\n",
    "    X_anomaly, y_anomaly = create_sequences(one_an_scaled, SEQUENCE_LENGTH)\n",
    "    X_anomaly_tensor = torch.from_numpy(X_anomaly).float()\n",
    "\n",
    "    return one_anomaly, X_anomaly_tensor, y_anomaly\n",
    "    \n",
    "def anomaly_check(one_anomaly):\n",
    "    print(\"LSTM Predictions Summary:\")\n",
    "    print(f\"Total points: {len(one_anomaly)}\")\n",
    "    print(f\"LSTM predicted anomalies: {(one_anomaly['lstm_prediction'] == 1).sum()}\")\n",
    "    print(f\"Ground truth anomalies: {(one_anomaly['y_true'] == 1).sum()}\")\n",
    "\n",
    "    # Calculate some basic metrics\n",
    "    true_positives = ((one_anomaly['y_true'] == 1) & (one_anomaly['lstm_prediction'] == 1)).sum()\n",
    "    false_positives = ((one_anomaly['y_true'] == 0) & (one_anomaly['lstm_prediction'] == 1)).sum()\n",
    "    false_negatives = ((one_anomaly['y_true'] == 1) & (one_anomaly['lstm_prediction'] == 0)).sum()\n",
    "\n",
    "    print(f\"True positives: {true_positives}\")\n",
    "    print(f\"False positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_loader, \n",
    "          loss_function,\n",
    "          optimizer,\n",
    "          X_anomaly_tensor, \n",
    "          one_anomaly):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Enable cudnn benchmarking for better performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Mixed precision training for better memory usage\n",
    "    # scaler_amp = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        num_batches = 0\n",
    "    \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        train_reconstruction_errors = []\n",
    "    \n",
    "        for batch_idx, (batch_x, _) in enumerate(pbar):\n",
    "            # Move batch to GPU\n",
    "            batch_x = batch_x.to(device)\n",
    "    \n",
    "            # Mixed precision forward pass\n",
    "            with torch.cuda.amp.autocast():\n",
    "                reconstructed = model(batch_x)\n",
    "                loss = loss_function(reconstructed, batch_x)\n",
    "    \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            # scaler_amp.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "            # scaler_amp.step(optimizer)\n",
    "            # scaler_amp.update()\n",
    "    \n",
    "            batch_errors = model.get_reconstruction_error(batch_x)\n",
    "            train_reconstruction_errors.extend(batch_errors)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "            # Update progress bar\n",
    "            if batch_idx % 10 == 0:\n",
    "                pbar.set_postfix({'loss': f'{train_loss/num_batches:.6f}'})\n",
    "    \n",
    "            # Clear cache periodically\n",
    "            if batch_idx % 100 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "\n",
    "        # val_loss = 0.0\n",
    "        # num_val_batches = 0\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     for batch_x, _ in val_loader:\n",
    "        #         batch_x = batch_x.to(device)\n",
    "        #         reconstructed = model(batch_x)\n",
    "        #         loss = loss_function(reconstructed, batch_x)\n",
    "        #         val_loss += loss.item()\n",
    "        #         num_val_batches += 1\n",
    "        #\n",
    "        # avg_train_loss = train_loss / num_batches\n",
    "        # avg_val_loss = val_loss / num_val_batches\n",
    "        #\n",
    "        # print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.6f}, Val Loss = {avg_val_loss:.6f}\")\n",
    "        #\n",
    "        # # Learning rate scheduling\n",
    "        # scheduler.step(avg_val_loss)\n",
    "        #\n",
    "        # # Early stopping\n",
    "        # if avg_val_loss < best_val_loss:\n",
    "        #     best_val_loss = avg_val_loss\n",
    "        #     patience_counter = 0\n",
    "        #     # Save best model\n",
    "        #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "        # else:\n",
    "        #     patience_counter += 1\n",
    "        #     if patience_counter >= PATIENCE:\n",
    "        #         print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        #         break\n",
    "    \n",
    "        # train_reconstruction_errors = model.get_reconstruction_error(X_train_tensor)\n",
    "        # threshold = np.percentile(train_reconstruction_errors, AUTOENCODER_THRESHOLD_PERCENTILE)\n",
    "    \n",
    "        train_reconstruction_errors = np.array(train_reconstruction_errors)\n",
    "        threshold = np.percentile(train_reconstruction_errors, AUTOENCODER_THRESHOLD_PERCENTILE)\n",
    "        print(f\"Anomaly threshold: {threshold:.6f}\")\n",
    "    \n",
    "        reconstruction_errors = model.get_reconstruction_error(X_anomaly_tensor)\n",
    "        print(f\"Anomaly reconstruction error: {reconstruction_errors}\")\n",
    "    \n",
    "        anomaly_mask = reconstruction_errors > threshold\n",
    "        anomaly_indices = np.where(anomaly_mask)[0]\n",
    "    \n",
    "        # Mark points as anomalous based on which sequences they belong to\n",
    "        for seq_idx in anomaly_indices:\n",
    "            start_point = seq_idx\n",
    "            end_point = min(seq_idx + SEQUENCE_LENGTH, len(one_anomaly))\n",
    "    \n",
    "            # Mark all points in this sequence as anomalous\n",
    "            one_anomaly.iloc[start_point:end_point, one_anomaly.columns.get_loc('lstm_prediction')] = 1\n",
    "    \n",
    "        anomaly_check(one_anomaly)\n",
    "    \n",
    "    # Load best model\n",
    "    # model.load_state_dict(torch.load('best_model.pth'))\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "def evaluate_model(model, train_loader):\n",
    "    model.eval()\n",
    "    train_reconstruction_errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, _ in train_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_errors = model.get_reconstruction_error(batch_x)\n",
    "            train_reconstruction_errors.extend(batch_errors)\n",
    "    \n",
    "    train_reconstruction_errors = np.array(train_reconstruction_errors)\n",
    "    threshold = np.percentile(train_reconstruction_errors, AUTOENCODER_THRESHOLD_PERCENTILE)\n",
    "    print(f\"Anomaly threshold: {threshold:.6f}\")\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load and devide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BREMERHAVEN\n",
      "Total trips: 702\n",
      "Normal trips: 650\n",
      "Anomaly trips: 14\n",
      "\n",
      "KIEL\n",
      "Total trips: 420\n",
      "Normal trips: 356\n",
      "Anomaly trips: 62\n"
     ]
    }
   ],
   "source": [
    "df_KIEL = load_data_route(\"KIEL\")\n",
    "df_BREM = load_data_route(\"BREMERHAVEN\")\n",
    "\n",
    "print(\"BREMERHAVEN\")\n",
    "df_normal_B, df_anomalies_B = divide_normal_anomaly(df_BREM)\n",
    "train_loader_B = get_data_loader(df_normal_B)\n",
    "\n",
    "print(\"\\nKIEL\")\n",
    "df_normal_K, df_anomalies_K = divide_normal_anomaly(df_KIEL)\n",
    "train_loader_K = get_data_loader(df_normal_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T14:28:41.537296869Z",
     "start_time": "2025-06-24T14:28:41.515513062Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "anomaly_B, X_anomaly_tensor_B, _ = get_anomaly_example(df_anomalies_B)\n",
    "anomaly_K, X_anomaly_tensor_K, _ = get_anomaly_example(df_anomalies_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configure and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_BREM = LSTMModel(input_size=len(FEATURE_COLUMNS), hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=len(FEATURE_COLUMNS))\n",
    "loss_function_BREM = nn.MSELoss()\n",
    "optimizer_BREM = torch.optim.Adam(model_BREM.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "model_KIEL = LSTMModel(input_size=len(FEATURE_COLUMNS), hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=len(FEATURE_COLUMNS))\n",
    "loss_function_KIEL = nn.MSELoss()\n",
    "optimizer_KIEL = torch.optim.Adam(model_KIEL.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Move to CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model_BREM = model_BREM.to(device)\n",
    "model_KIEL = model_KIEL.to(device)\n",
    "\n",
    "\n",
    "X_anomaly_tensor_B = X_anomaly_tensor_B.to(device)\n",
    "X_anomaly_tensor_K = X_anomaly_tensor_K.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model_BREM, train_loader_B, loss_function_BREM, optimizer_BREM, X_anomaly_tensor_B, anomaly_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly threshold: 0.025404\n"
     ]
    }
   ],
   "source": [
    "trashhold_BREM = evaluate_model(model_BREM, train_loader_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model_KIEL, train_loader_K, loss_function_KIEL, optimizer_KIEL, X_anomaly_tensor_K, anomaly_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate_model() missing 1 required positional argument: 'train_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trashhold_KEIL \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_KIEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_model() missing 1 required positional argument: 'train_loader'"
     ]
    }
   ],
   "source": [
    "trashhold_KEIL = evaluate_model(model_KIEL, train_loader_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # Prepare anomaly data\n",
    "# anomaly_data = one_anomaly[FEATURE_COLUMNS].values\n",
    "# anomaly_data_scaled = scaler.transform(anomaly_data)\n",
    "#\n",
    "# if len(anomaly_data_scaled) >= SEQUENCE_LENGTH:\n",
    "#     X_anomaly, _ = create_sequences(anomaly_data_scaled, SEQUENCE_LENGTH)\n",
    "#\n",
    "#     # Process in batches to avoid OOM\n",
    "#     batch_size_test = 64\n",
    "#     anomaly_mask = []\n",
    "#\n",
    "#     for i in range(0, len(X_anomaly), batch_size_test):\n",
    "#         batch = X_anomaly[i:i+batch_size_test]\n",
    "#         batch_tensor = torch.FloatTensor(batch).to(device)\n",
    "#\n",
    "#         with torch.no_grad():\n",
    "#             batch_errors = model.get_reconstruction_error(batch_tensor)\n",
    "#             batch_mask = batch_errors > threshold\n",
    "#             anomaly_mask.extend(batch_mask)\n",
    "#\n",
    "#         # Clear cache after each batch\n",
    "#         torch.cuda.empty_cache()\n",
    "#\n",
    "#     anomaly_mask = np.array(anomaly_mask)\n",
    "#     anomaly_indices = np.where(anomaly_mask)[0]\n",
    "#\n",
    "#     # Initialize prediction column\n",
    "#     one_anomaly['lstm_prediction'] = 0\n",
    "#\n",
    "#     # Mark anomalous sequences\n",
    "#     for seq_idx in anomaly_indices:\n",
    "#         start_point = seq_idx\n",
    "#         end_point = min(seq_idx + SEQUENCE_LENGTH, len(one_anomaly))\n",
    "#         one_anomaly.iloc[start_point:end_point, one_anomaly.columns.get_loc('lstm_prediction')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Save to file\n",
    "output_dir = Path(\"models_per_route_lstm_ae\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def save_model(model, scaler, threshold, route_name):\n",
    "    # Move model to CPU before saving\n",
    "    model.cpu()\n",
    "    \n",
    "    # Save everything needed for inference\n",
    "    lstm_artifacts = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"scaler\": scaler,\n",
    "        \"threshold\": threshold,\n",
    "        \"model_config\": {\n",
    "            \"input_size\": len(FEATURE_COLUMNS),\n",
    "            \"hidden_size\": HIDDEN_SIZE, \n",
    "            \"num_layers\": NUM_LAYERS,\n",
    "            \"sequence_length\": SEQUENCE_LENGTH,\n",
    "            \"threshold_percentile\": AUTOENCODER_THRESHOLD_PERCENTILE\n",
    "        },\n",
    "        \"features\": FEATURE_COLUMNS,\n",
    "        \"model_type\": \"lstm\"\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Save for the specific route\n",
    "    model_filename = output_dir / f\"{route_name}_lstm_model.pkl\"\n",
    "    joblib.dump(lstm_artifacts, model_filename)\n",
    "\n",
    "    print(f\"LSTM model saved to {model_filename}\")\n",
    "    return model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models_filenames = []\n",
    "dispatcher_lstm = {}\n",
    "\n",
    "# Save BREMERHAVEN model\n",
    "model_filename_BREM = save_model(model_BREM, scaler, trashhold_BREM, \"BREMERHAVEN\")\n",
    "models_filenames.append(model_filename_BREM)\n",
    "dispatcher_lstm[\"BREMERHAVEN\"] = str(model_filename_BREM)\n",
    "\n",
    "# Save KIEL model\n",
    "model_filename_KIEL = save_model(model_KIEL, scaler, trashhold_KIEL, \"KIEL\")\n",
    "models_filenames.append(model_filename_KIEL)\n",
    "dispatcher_lstm[\"KIEL\"] = str(model_filename_KIEL)\n",
    "\n",
    "# Save dispatcher\n",
    "dispatcher_file = output_dir / \"dispatcher.pkl\"\n",
    "joblib.dump(dispatcher_lstm, dispatcher_file)\n",
    "print(f\"Dispatcher saved to {dispatcher_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

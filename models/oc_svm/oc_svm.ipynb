{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.238500905Z",
     "start_time": "2025-06-17T17:02:15.597384352Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282095083Z",
     "start_time": "2025-06-17T17:02:17.278796550Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuration:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ───────────────────────────── configuration ────────────────────────────── #\n",
    "# List of trip IDs to drop from the dataset\n",
    "DROP_TRIPS      = [10257]\n",
    "# Base columns used for training the OC-SVM\n",
    "BASE_COLUMNS    = [\n",
    "    \"speed_over_ground\", \"dv\", \"dcourse\", \"ddraft\",\n",
    "    \"zone\",\n",
    "    \"x_km\", \"y_km\", \"dist_to_ref\", \"route_dummy\"\n",
    "]\n",
    "\n",
    "# Geographical zones defined by [lat_max, lat_min, lon_max, lon_min]\n",
    "ZONES           = [[53.8, 53.5, 8.6, 8.14], [53.66, 53.0, 11.0, 9.5]]\n",
    "\n",
    "# Radii (in km) defining \"port\" and \"approach\" zones (currently unused in logic)\n",
    "R_PORT, R_APP   = 5.0, 15.0\n",
    "# Earth radius in km, used for haversine distance calculation\n",
    "EARTH_R         = 6_371.0\n",
    "\n",
    "# Cross-validation settings\n",
    "CV_FOLDS = 3\n",
    "RANDOM_STATE = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282267443Z",
     "start_time": "2025-06-17T17:02:17.278912516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for data preparation and feature engineering:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Vectorized haversine distance (km).\"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, (lat1, lon1, lat2, lon2))\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_R * np.arcsin(np.sqrt(a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282324891Z",
     "start_time": "2025-06-17T17:02:17.278962702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_and_prepare(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load parquet, drop specified trips, parse dates, compute delta-features,\n",
    "    map labels and one-hot port zones.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(path, engine=\"pyarrow\")\n",
    "    print(f\"Loaded {len(df):,} rows, dropping {len(df[df.trip_id.isin(DROP_TRIPS)]):,} rows from {DROP_TRIPS}\")\n",
    "    df = df[~df.trip_id.isin(DROP_TRIPS)].reset_index(drop=True)\n",
    "\n",
    "    for col in (\"start_time\", \"end_time\", \"time_stamp\"):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    df = df.dropna(subset=[\"ship_type\"]).reset_index(drop=True)\n",
    "    df[\"y_true\"]   = df[\"is_anomaly\"].map({True: 1, False: 0})\n",
    "    df[\"route_id\"] = df[\"start_port\"] # Using start_port as route_id for this pipeline\n",
    "\n",
    "    # per-point deltas\n",
    "    df = df.sort_values([\"trip_id\", \"time_stamp\"])\n",
    "    df[\"dv\"]      = df.groupby(\"trip_id\")[\"speed_over_ground\"].diff().abs().fillna(0)\n",
    "    df[\"dcourse\"] = df.groupby(\"trip_id\")[\"course_over_ground\"].diff().abs().fillna(0)\n",
    "    df[\"ddraft\"]  = df.groupby(\"trip_id\")[\"draught\"].diff().abs().fillna(0)\n",
    "\n",
    "    # zones\n",
    "    # port_coords is defined but not used in zone_label; it might be a remnant\n",
    "    port_coords = (\n",
    "        df.groupby(\"start_port\")[[\"start_latitude\", \"start_longitude\"]]\n",
    "          .first()\n",
    "          .to_dict(\"index\")\n",
    "    )\n",
    "\n",
    "    def _in_any_rect(lat: float, lon: float) -> bool:\n",
    "        \"\"\"Checks if a given lat/lon is within any of the defined rectangular zones.\"\"\"\n",
    "        for lat_max, lat_min, lon_max, lon_min in ZONES:\n",
    "            if lat_min <= lat <= lat_max and lon_min <= lon <= lon_max:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def zone_label(row) -> int:\n",
    "        \"\"\"Assigns a zone label (0 for within zone, 1 for outside).\"\"\"\n",
    "        if _in_any_rect(row.latitude, row.longitude):\n",
    "            return 0 # In a defined zone\n",
    "        return 1 # Outside all defined zones\n",
    "\n",
    "    df[\"zone\"] = df.progress_apply(zone_label, axis=1)\n",
    "    # One-hot encode the 'zone' column. Note: this line is creating 'zone_0' and 'zone_1'\n",
    "    # but only 'zone' (the numerical label) is used in BASE_COLUMNS.\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"zone\"], prefix=\"zone\")], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282365062Z",
     "start_time": "2025-06-17T17:02:17.279013216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_average_route(df_route: pd.DataFrame, n_points: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute average trajectory for a route by resampling each trip to n_points\n",
    "    along cumulative distance fraction, then averaging.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    for _, trip in df_route.groupby(\"trip_id\"):\n",
    "        trip = trip.sort_values(\"time_stamp\")\n",
    "        lat, lon = trip.latitude.to_numpy(), trip.longitude.to_numpy()\n",
    "        d = haversine(lat[1:], lon[1:], lat[:-1], lon[:-1])\n",
    "        cum = np.concatenate(([0], np.cumsum(d)))\n",
    "        if cum[-1] <= 0: # Handle cases with no movement within the trip\n",
    "            continue\n",
    "        frac   = cum / cum[-1]\n",
    "        target = np.linspace(0, 1, n_points)\n",
    "        segments.append(np.vstack([np.interp(target, frac, lat),\n",
    "                                   np.interp(target, frac, lon)]).T)\n",
    "    if not segments: # If no valid segments were found for the route\n",
    "        return np.array([]) # Return an empty array or handle as error\n",
    "    return np.mean(np.stack(segments, axis=0), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282402739Z",
     "start_time": "2025-06-17T17:02:17.279073514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def add_route_specific_features(df: pd.DataFrame, route: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a single route:\n",
    "    • project lat/lon to local x_km, y_km\n",
    "    • compute distance to average route (dist_to_ref)\n",
    "    • add constant route_dummy = 1\n",
    "    \"\"\"\n",
    "    df_r = df[df.route_id == route].copy()\n",
    "\n",
    "    # local projection\n",
    "    lat0, lon0 = df_r.latitude.mean(), df_r.longitude.mean()\n",
    "    kx = 111.320 * np.cos(np.deg2rad(lat0)) # Conversion factor for longitude to km\n",
    "    ky = 110.574 # Conversion factor for latitude to km\n",
    "    df_r[\"x_km\"] = (df_r.longitude - lon0) * kx\n",
    "    df_r[\"y_km\"] = (df_r.latitude  - lat0) * ky\n",
    "\n",
    "    # distance to average trajectory\n",
    "    avg = compute_average_route(df_r)\n",
    "    if avg.size == 0: # Handle case where average route couldn't be computed\n",
    "        df_r[\"dist_to_ref\"] = 0.0 # Or fill with NaN, depending on desired behavior\n",
    "        df_r[\"route_dummy\"] = 1.0\n",
    "        return df_r\n",
    "\n",
    "    idx_map = df_r.index\n",
    "    frac = np.zeros(len(df_r))\n",
    "    for _, trip in tqdm(df_r.groupby(\"trip_id\"), desc=f\"Processing trips for route {route}\"):\n",
    "        pos = idx_map.get_indexer(trip.index)\n",
    "        lat, lon = trip.latitude.values, trip.longitude.values\n",
    "        d = haversine(lat[1:], lon[1:], lat[:-1], lon[:-1])\n",
    "        cum = np.concatenate(([0], np.cumsum(d)))\n",
    "        total = cum[-1] if cum[-1] > 0 else 1\n",
    "        frac[pos] = cum / total\n",
    "\n",
    "    # Ensure index for avg is within bounds (0 to 99 for 100 points)\n",
    "    df_r[\"dist_to_ref\"] = [\n",
    "        haversine(lat, lon, avg[int(f * 99), 0], avg[int(f * 99), 1])\n",
    "        for lat, lon, f in zip(df_r.latitude, df_r.longitude, frac)\n",
    "    ]\n",
    "    df_r[\"route_dummy\"] = 1.0\n",
    "    return df_r"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.282439580Z",
     "start_time": "2025-06-17T17:02:17.279175774Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Evaluation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fucntions for model evaluation & cross-validation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "\n",
    "\n",
    "def evaluate_model(pipeline, X_train, X_test, y_test, nu, tau) -> Dict[str, float]:\n",
    "    \"\"\"Comprehensive model evaluation with multiple metrics.\"\"\"\n",
    "    scores_test = -pipeline.decision_function(X_test)\n",
    "    preds = (scores_test > tau).astype(int)\n",
    "\n",
    "    # Basic metrics\n",
    "    if len(np.unique(y_test)) > 1:\n",
    "        auc_roc = roc_auc_score(y_test, scores_test)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, scores_test)\n",
    "        auc_pr = auc(recall, precision)\n",
    "    else:\n",
    "        auc_roc = auc_pr = 0.0\n",
    "\n",
    "    # Confusion matrix metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel() if len(np.unique(y_test)) > 1 else (len(y_test), 0, 0, 0)\n",
    "\n",
    "    metrics = {\n",
    "        'auc_roc': auc_roc,\n",
    "        'auc_pr': auc_pr,\n",
    "        'precision': tp / (tp + fp) if (tp + fp) > 0 else 0.0,\n",
    "        'recall': tp / (tp + fn) if (tp + fn) > 0 else 0.0,\n",
    "        'f1': 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0,\n",
    "        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0.0,\n",
    "        'balanced_accuracy': 0.5 * (tp / (tp + fn) + tn / (tn + fp)) if (tp + fn) > 0 and (tn + fp) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.288281962Z",
     "start_time": "2025-06-17T17:02:17.283856014Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def cross_validate_ocsvm(X_norm, X_test, y_test, params, cv_folds=3):\n",
    "    \"\"\"Cross-validation for One-Class SVM parameter selection.\"\"\"\n",
    "    # Create train/validation splits from normal data\n",
    "    n_samples = len(X_norm)\n",
    "    indices = np.arange(n_samples)\n",
    "\n",
    "    fold_size = n_samples // cv_folds\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold in range(cv_folds):\n",
    "        # Create validation split\n",
    "        val_start = fold * fold_size\n",
    "        val_end = (fold + 1) * fold_size if fold < cv_folds - 1 else n_samples\n",
    "\n",
    "        val_indices = indices[val_start:val_end]\n",
    "        train_indices = np.concatenate([indices[:val_start], indices[val_end:]])\n",
    "\n",
    "        X_train_fold = X_norm[train_indices]\n",
    "        X_val_fold = X_norm[val_indices]\n",
    "\n",
    "        # Train model\n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", params['scaler']),\n",
    "            (\"ocsvm\", OneClassSVM(\n",
    "                kernel=params['kernel'],\n",
    "                gamma=params['gamma'],\n",
    "                nu=params['nu'],\n",
    "                verbose=False,\n",
    "                shrinking=False\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train_fold)\n",
    "\n",
    "        # Compute threshold on training data\n",
    "        scores_train = -pipeline.decision_function(X_train_fold)\n",
    "        tau = np.percentile(scores_train, 100 * (1 - params['nu']))\n",
    "\n",
    "        # Evaluate on validation set (treating as potential anomalies)\n",
    "        scores_val = -pipeline.decision_function(X_val_fold)\n",
    "        # For validation, we expect most points to be normal, so we use a simple outlier score\n",
    "        val_score = np.mean(scores_val < tau)  # Fraction classified as normal\n",
    "\n",
    "        cv_scores.append(val_score)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.294248945Z",
     "start_time": "2025-06-17T17:02:17.291340483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def comprehensive_parameter_search(X_norm, X_test, y_test, grid_name='focused_rbf', use_cv=True):\n",
    "    \"\"\"\n",
    "    Comprehensive parameter search for One-Class SVM.\n",
    "\n",
    "    Args:\n",
    "        X_norm: Normal training data\n",
    "        X_test: Test data (mixed normal/anomaly)\n",
    "        y_test: Test labels\n",
    "        grid_name: Which parameter grid to use\n",
    "        use_cv: Whether to use cross-validation for parameter selection\n",
    "    \"\"\"\n",
    "    param_grid = PARAMETER_GRIDS[grid_name]\n",
    "\n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    param_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "    print(f\"Searching {len(param_combinations)} parameter combinations...\")\n",
    "\n",
    "    results = []\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    best_pipeline = None\n",
    "    best_tau = None\n",
    "\n",
    "    with tqdm(param_combinations, desc=\"Parameter search\") as pbar:\n",
    "        for params in pbar:\n",
    "            param_dict = dict(zip(param_names, params))\n",
    "\n",
    "            try:\n",
    "                # Create pipeline\n",
    "                pipeline = Pipeline([\n",
    "                    (\"scaler\", param_dict['scaler']),\n",
    "                    (\"ocsvm\", OneClassSVM(\n",
    "                        kernel=param_dict['kernel'],\n",
    "                        gamma=param_dict['gamma'],\n",
    "                        nu=param_dict['nu'],\n",
    "                        verbose=False,\n",
    "                        shrinking=False\n",
    "                    ))\n",
    "                ])\n",
    "\n",
    "                # Fit on normal data\n",
    "                pipeline.fit(X_norm)\n",
    "\n",
    "                # Compute threshold\n",
    "                scores_train = -pipeline.decision_function(X_norm)\n",
    "                tau = np.percentile(scores_train, 100 * (1 - param_dict['nu']))\n",
    "\n",
    "                # Evaluate\n",
    "                if use_cv:\n",
    "                    # Use cross-validation score as primary metric\n",
    "                    cv_score = cross_validate_ocsvm(X_norm, X_test, y_test, param_dict, CV_FOLDS)\n",
    "                    primary_score = cv_score\n",
    "                else:\n",
    "                    # Use test AUC as primary metric\n",
    "                    metrics = evaluate_model(pipeline, X_norm, X_test, y_test, param_dict['nu'], tau)\n",
    "                    primary_score = metrics['auc_roc']\n",
    "\n",
    "                # Full evaluation on test set\n",
    "                test_metrics = evaluate_model(pipeline, X_norm, X_test, y_test, param_dict['nu'], tau)\n",
    "\n",
    "                result = {\n",
    "                    'params': param_dict.copy(),\n",
    "                    'primary_score': primary_score,\n",
    "                    'tau': tau,\n",
    "                    **test_metrics\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "                # Update best\n",
    "                if primary_score > best_score:\n",
    "                    best_score = primary_score\n",
    "                    best_params = param_dict.copy()\n",
    "                    best_pipeline = pipeline\n",
    "                    best_tau = tau\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'best_score': f'{best_score:.3f}',\n",
    "                    'current': f'{primary_score:.3f}'\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with params {param_dict}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Sort results by primary score\n",
    "    results.sort(key=lambda x: x['primary_score'], reverse=True)\n",
    "\n",
    "    return {\n",
    "        'best_pipeline': best_pipeline,\n",
    "        'best_params': best_params,\n",
    "        'best_tau': best_tau,\n",
    "        'best_score': best_score,\n",
    "        'all_results': results\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.328346112Z",
     "start_time": "2025-06-17T17:02:17.302853883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def print_search_results(search_results, top_k=5):\n",
    "    \"\"\"Print formatted results from parameter search.\"\"\"\n",
    "    results = search_results['all_results']\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PARAMETER SEARCH RESULTS - TOP {top_k}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for i, result in enumerate(results[:top_k]):\n",
    "        print(f\"\\nRank {i+1}:\")\n",
    "        print(f\"  Primary Score: {result['primary_score']:.4f}\")\n",
    "        print(f\"  AUC-ROC: {result['auc_roc']:.4f}\")\n",
    "        print(f\"  AUC-PR: {result['auc_pr']:.4f}\")\n",
    "        print(f\"  F1: {result['f1']:.4f}\")\n",
    "        print(f\"  Balanced Accuracy: {result['balanced_accuracy']:.4f}\")\n",
    "        print(f\"  Threshold (τ): {result['tau']:.4f}\")\n",
    "\n",
    "        params = result['params']\n",
    "        print(f\"  Parameters:\")\n",
    "        print(f\"    nu: {params['nu']}\")\n",
    "        print(f\"    gamma: {params['gamma']}\")\n",
    "        print(f\"    kernel: {params['kernel']}\")\n",
    "        print(f\"    scaler: {type(params['scaler']).__name__}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.328508401Z",
     "start_time": "2025-06-17T17:02:17.307366738Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start the training and evaluation process:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Configure parameter grids for search:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "PARAMETER_GRIDS = {\n",
    "    'comprehensive': {\n",
    "        'nu': [0.001, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.15, 0.2],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "        'scaler': [StandardScaler(), RobustScaler(), MinMaxScaler()]\n",
    "    },\n",
    "    'focused_rbf': {\n",
    "        'nu': [0.001, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1.0],\n",
    "        'kernel': ['rbf'],\n",
    "        'scaler': [StandardScaler(), RobustScaler()]\n",
    "    },\n",
    "    'quick': {\n",
    "        'nu': [0.01, 0.03],\n",
    "        'gamma': ['scale'],\n",
    "        'kernel': ['rbf'],\n",
    "        'scaler': [StandardScaler()]\n",
    "    }\n",
    "}\n",
    "# Fraction of normal points to include in the test set\n",
    "TEST_FRACTION_N = 0.10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:02:17.391481128Z",
     "start_time": "2025-06-17T17:02:17.312026447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 912,566 rows, dropping 577 rows from [10257]\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/911621 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c892014f51e14b3287585538e4cb43b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_dir: str = \"models_per_route\"\n",
    "df = load_and_prepare(\"all_trips_saved.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:03:35.549401465Z",
     "start_time": "2025-06-17T17:03:17.540669132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'KIEL'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route = df.route_id.unique()[0]\n",
    "# route = df[df.route_id == df.route_id.unique()[1]]\n",
    "grid_name='quick'\n",
    "route"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:03:37.985140416Z",
     "start_time": "2025-06-17T17:03:37.966633277Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Start training for the specified route:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training route: KIEL with quick search ===\n"
     ]
    },
    {
     "data": {
      "text/plain": "Processing trips for route KIEL:   0%|          | 0/420 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a449a9dfa8e47eb98c1dbfb625fd32b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Path(out_dir).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\n=== Training route: {route} with {grid_name} search ===\")\n",
    "t0 = time.time()\n",
    "\n",
    "# Prepare route data\n",
    "fr = add_route_specific_features(df, route)\n",
    "X_norm = fr[fr.y_true == 0][BASE_COLUMNS].fillna(0).values\n",
    "X_anom = fr[fr.y_true == 1][BASE_COLUMNS].fillna(0).values\n",
    "\n",
    "if len(X_norm) == 0:\n",
    "    print(\"  * No normal points, skipping this route.\")\n",
    "\n",
    "# Prepare test set\n",
    "idx_anom = fr[fr.y_true == 1].index.to_numpy()\n",
    "n_norm_test = max(1, int(TEST_FRACTION_N * len(X_norm)))\n",
    "idx_norm = fr[fr.y_true == 0].sample(n=n_norm_test, random_state=RANDOM_STATE).index.to_numpy()\n",
    "\n",
    "X_test = np.vstack([\n",
    "    fr.loc[idx_anom, BASE_COLUMNS].fillna(0).values,\n",
    "    fr.loc[idx_norm, BASE_COLUMNS].fillna(0).values\n",
    "])\n",
    "y_test = np.concatenate([\n",
    "    np.ones(len(idx_anom), dtype=int),\n",
    "    np.zeros(len(idx_norm), dtype=int)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:03:44.911860186Z",
     "start_time": "2025-06-17T17:03:39.035639964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 2 parameter combinations...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Parameter search:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec3e85663c334037afab6d53253234d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PARAMETER SEARCH RESULTS - TOP 5\n",
      "================================================================================\n",
      "\n",
      "Rank 1:\n",
      "  Primary Score: 0.9646\n",
      "  AUC-ROC: 0.9874\n",
      "  AUC-PR: 0.9597\n",
      "  F1: 0.8514\n",
      "  Balanced Accuracy: 0.9655\n",
      "  Threshold (τ): 0.0000\n",
      "  Parameters:\n",
      "    nu: 0.01\n",
      "    gamma: scale\n",
      "    kernel: rbf\n",
      "    scaler: StandardScaler\n",
      "\n",
      "Rank 2:\n",
      "  Primary Score: 0.9443\n",
      "  AUC-ROC: 0.9905\n",
      "  AUC-PR: 0.9667\n",
      "  F1: 0.7652\n",
      "  Balanced Accuracy: 0.9694\n",
      "  Threshold (τ): 0.0000\n",
      "  Parameters:\n",
      "    nu: 0.03\n",
      "    gamma: scale\n",
      "    kernel: rbf\n",
      "    scaler: StandardScaler\n"
     ]
    }
   ],
   "source": [
    "search_results = comprehensive_parameter_search(X_norm, X_test, y_test, grid_name)\n",
    "print_search_results(search_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:05:20.755415351Z",
     "start_time": "2025-06-17T17:03:46.377813364Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final evaluation and model saving:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL EVALUATION ===\n",
      "Best parameters: {'nu': 0.01, 'gamma': 'scale', 'kernel': 'rbf', 'scaler': StandardScaler()}\n",
      "Confusion Matrix:\n",
      "[[7818  164]\n",
      " [  28  550]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.979     0.988      7982\n",
      "           1      0.770     0.952     0.851       578\n",
      "\n",
      "    accuracy                          0.978      8560\n",
      "   macro avg      0.883     0.966     0.920      8560\n",
      "weighted avg      0.981     0.978     0.979      8560\n",
      "\n",
      "Route KIEL completed in 122.0s\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "best_pipeline = search_results['best_pipeline']\n",
    "best_tau = search_results['best_tau']\n",
    "best_params = search_results['best_params']\n",
    "\n",
    "scores_test = -best_pipeline.decision_function(X_test)\n",
    "preds = (scores_test > best_tau).astype(int)\n",
    "\n",
    "print(f\"\\n=== FINAL EVALUATION ===\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(f\"Classification Report:\")\n",
    "print(classification_report(y_test, preds, digits=3))\n",
    "print(f\"Route {route} completed in {time.time() - t0:.1f}s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:05:41.044361410Z",
     "start_time": "2025-06-17T17:05:40.617664115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['models_per_route/ocsvm_KIEL.pkl']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save model\n",
    "model_path = Path(out_dir) / f\"ocsvm_{route}.pkl\"\n",
    "joblib.dump({\n",
    "    \"pipeline\": best_pipeline,\n",
    "    \"features\": BASE_COLUMNS,\n",
    "    \"tau\": best_tau,\n",
    "    \"params\": best_params,\n",
    "    \"search_results\": search_results\n",
    "}, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-17T17:05:43.074747427Z",
     "start_time": "2025-06-17T17:05:43.032172231Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

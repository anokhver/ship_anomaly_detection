{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:08:58.380065142Z",
     "start_time": "2025-06-06T20:08:58.356745261Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pandas.api.types import infer_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1\n",
    "Load the cvs file with cleaned attributes.\n",
    "Check the beginning of the file to ensure it is loaded correctly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   TripID  StartLatitude  StartLongitude           StartTime  EndLatitude  \\\n0   39131          53.57            8.53  '2016-01-24 08:06'        53.53   \n1   39131          53.57            8.53  '2016-01-24 08:06'        53.53   \n2   39131          53.57            8.53  '2016-01-24 08:06'        53.53   \n3   39131          53.57            8.53  '2016-01-24 08:06'        53.53   \n4   39131          53.57            8.53  '2016-01-24 08:06'        53.53   \n\n   EndLongitude             EndTime    StartPort  EndPort  \\\n0           9.9  '2016-01-24 16:44'  BREMERHAVEN  HAMBURG   \n1           9.9  '2016-01-24 16:44'  BREMERHAVEN  HAMBURG   \n2           9.9  '2016-01-24 16:44'  BREMERHAVEN  HAMBURG   \n3           9.9  '2016-01-24 16:44'  BREMERHAVEN  HAMBURG   \n4           9.9  '2016-01-24 16:44'  BREMERHAVEN  HAMBURG   \n\n                        time  ...  Length  Breadth  Draught  Latitude  \\\n0  2016-01-24 09:07:00+01:00  ...     277       42    11.54     53.57   \n1  2016-01-24 09:10:00+01:00  ...     277       42    11.54     53.57   \n2  2016-01-24 09:10:00+01:00  ...     277       42    11.54     53.57   \n3  2016-01-24 09:12:00+01:00  ...     277       42    11.54     53.57   \n4  2016-01-24 09:16:00+01:00  ...     277       42    11.54     53.57   \n\n   Longitude  SOG    COG   TH  Destination            AisSourcen  \n0       8.53  0.7  331.2  143      HAMBURG  DAIS1.81b.90b.71.71a  \n1       8.53  1.6  315.3  117      HAMBURG  DAIS1.81b.90b.71.71a  \n2       8.53  2.8  322.6  100      HAMBURG  DAIS1.81b.90b.71.71a  \n3       8.53  2.8  286.3   74      HAMBURG  DAIS1.81b.90b.71.71a  \n4       8.53  4.3  333.1  333      HAMBURG  DAIS1.81b.90b.71.71a  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TripID</th>\n      <th>StartLatitude</th>\n      <th>StartLongitude</th>\n      <th>StartTime</th>\n      <th>EndLatitude</th>\n      <th>EndLongitude</th>\n      <th>EndTime</th>\n      <th>StartPort</th>\n      <th>EndPort</th>\n      <th>time</th>\n      <th>...</th>\n      <th>Length</th>\n      <th>Breadth</th>\n      <th>Draught</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>SOG</th>\n      <th>COG</th>\n      <th>TH</th>\n      <th>Destination</th>\n      <th>AisSourcen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39131</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>'2016-01-24 08:06'</td>\n      <td>53.53</td>\n      <td>9.9</td>\n      <td>'2016-01-24 16:44'</td>\n      <td>BREMERHAVEN</td>\n      <td>HAMBURG</td>\n      <td>2016-01-24 09:07:00+01:00</td>\n      <td>...</td>\n      <td>277</td>\n      <td>42</td>\n      <td>11.54</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>0.7</td>\n      <td>331.2</td>\n      <td>143</td>\n      <td>HAMBURG</td>\n      <td>DAIS1.81b.90b.71.71a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39131</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>'2016-01-24 08:06'</td>\n      <td>53.53</td>\n      <td>9.9</td>\n      <td>'2016-01-24 16:44'</td>\n      <td>BREMERHAVEN</td>\n      <td>HAMBURG</td>\n      <td>2016-01-24 09:10:00+01:00</td>\n      <td>...</td>\n      <td>277</td>\n      <td>42</td>\n      <td>11.54</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>1.6</td>\n      <td>315.3</td>\n      <td>117</td>\n      <td>HAMBURG</td>\n      <td>DAIS1.81b.90b.71.71a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39131</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>'2016-01-24 08:06'</td>\n      <td>53.53</td>\n      <td>9.9</td>\n      <td>'2016-01-24 16:44'</td>\n      <td>BREMERHAVEN</td>\n      <td>HAMBURG</td>\n      <td>2016-01-24 09:10:00+01:00</td>\n      <td>...</td>\n      <td>277</td>\n      <td>42</td>\n      <td>11.54</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>2.8</td>\n      <td>322.6</td>\n      <td>100</td>\n      <td>HAMBURG</td>\n      <td>DAIS1.81b.90b.71.71a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39131</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>'2016-01-24 08:06'</td>\n      <td>53.53</td>\n      <td>9.9</td>\n      <td>'2016-01-24 16:44'</td>\n      <td>BREMERHAVEN</td>\n      <td>HAMBURG</td>\n      <td>2016-01-24 09:12:00+01:00</td>\n      <td>...</td>\n      <td>277</td>\n      <td>42</td>\n      <td>11.54</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>2.8</td>\n      <td>286.3</td>\n      <td>74</td>\n      <td>HAMBURG</td>\n      <td>DAIS1.81b.90b.71.71a</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39131</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>'2016-01-24 08:06'</td>\n      <td>53.53</td>\n      <td>9.9</td>\n      <td>'2016-01-24 16:44'</td>\n      <td>BREMERHAVEN</td>\n      <td>HAMBURG</td>\n      <td>2016-01-24 09:16:00+01:00</td>\n      <td>...</td>\n      <td>277</td>\n      <td>42</td>\n      <td>11.54</td>\n      <td>53.57</td>\n      <td>8.53</td>\n      <td>4.3</td>\n      <td>333.1</td>\n      <td>333</td>\n      <td>HAMBURG</td>\n      <td>DAIS1.81b.90b.71.71a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the file path to move up one directory\n",
    "file_path = '../../data/cleaned_atr.csv'\n",
    "output_path = '../data/1_type_norm.parquet'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Load the file if it exists\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:00.738052302Z",
     "start_time": "2025-06-06T20:08:58.362058083Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2\n",
    "   Assign proper data types to columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "TripID              int64\nStartLatitude     float64\nStartLongitude    float64\nStartTime          object\nEndLatitude       float64\nEndLongitude      float64\nEndTime            object\nStartPort          object\nEndPort            object\ntime               object\nshiptype            int64\nLength              int64\nBreadth             int64\nDraught           float64\nLatitude          float64\nLongitude         float64\nSOG               float64\nCOG               float64\nTH                  int64\nDestination        object\nAisSourcen         object\ndtype: object"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:00.738644577Z",
     "start_time": "2025-06-06T20:09:00.736652343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "StartTime      object\nEndTime        object\nStartPort      object\nEndPort        object\ntime           object\nDestination    object\nAisSourcen     object\ndtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes[df.dtypes == 'object'] # Printing all with 'object' type"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:00.738877121Z",
     "start_time": "2025-06-06T20:09:00.736851463Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some 'object' columns are labeled that way because pandas can't automatically infer their true type,\n",
    "even though all values may actually be the same type (e.g., all strings).\n",
    "In other cases, the column truly has mixed types—like a mix of strings and floats—which can cause issues later.\n",
    "So we need to check for mixed types in these columns and convert them to a consistent type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Destination' has mixed types: [<class 'str'> <class 'float'>]\n",
      "Examples of string values in 'Destination':\n",
      "0    HAMBURG\n",
      "1    HAMBURG\n",
      "2    HAMBURG\n",
      "3    HAMBURG\n",
      "4    HAMBURG\n",
      "Name: Destination, dtype: object\n",
      "Examples of float values in 'Destination':\n",
      "243332    NaN\n",
      "243333    NaN\n",
      "480142    NaN\n",
      "480143    NaN\n",
      "480144    NaN\n",
      "Name: Destination, dtype: object\n",
      "Column 'AisSourcen' has mixed types: [<class 'str'> <class 'float'>]\n",
      "Examples of string values in 'AisSourcen':\n",
      "0    DAIS1.81b.90b.71.71a\n",
      "1    DAIS1.81b.90b.71.71a\n",
      "2    DAIS1.81b.90b.71.71a\n",
      "3    DAIS1.81b.90b.71.71a\n",
      "4    DAIS1.81b.90b.71.71a\n",
      "Name: AisSourcen, dtype: object\n",
      "Examples of float values in 'AisSourcen':\n",
      "1048    NaN\n",
      "1049    NaN\n",
      "1050    NaN\n",
      "1051    NaN\n",
      "1052    NaN\n",
      "Name: AisSourcen, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "['Destination', 'AisSourcen']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_mixed_types_and_examples(df):\n",
    "    mixed = []\n",
    "    for column in df.columns:\n",
    "        unique_types = df[column].apply(type).unique()\n",
    "        if len(unique_types) > 1:\n",
    "            print(f\"Column '{column}' has mixed types: {unique_types}\")\n",
    "            # Display examples of string and float values\n",
    "            string_values = df[column][df[column].apply(type) == str].head()\n",
    "            float_values = df[column][df[column].apply(type) == float].head()\n",
    "            print(f\"Examples of string values in '{column}':\\n{string_values}\")\n",
    "            print(f\"Examples of float values in '{column}':\\n{float_values}\")\n",
    "            mixed.append(column)\n",
    "    return mixed\n",
    "\n",
    "check_mixed_types_and_examples(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:02.730673757Z",
     "start_time": "2025-06-06T20:09:00.736987662Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**So we can see that the problem was with NaN values that are interpreted as float. We will convert the columns to string type to avoid mixed types issues.**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Destination'] = df['Destination'].fillna(\"nan\").astype('string')\n",
    "df['AisSourcen'] = df['AisSourcen'].fillna(\"nan\").astype('string')\n",
    "check_mixed_types_and_examples(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:04.317622524Z",
     "start_time": "2025-06-06T20:09:02.753889683Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets check the 'object' type data with no issue of types mixing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: StartTime, Example: '2016-01-24 08:06'\n",
      "Column: EndTime, Example: '2016-01-24 16:44'\n",
      "Column: StartPort, Example: BREMERHAVEN\n",
      "Column: EndPort, Example: HAMBURG\n",
      "Column: time, Example: 2016-01-24 09:07:00+01:00\n"
     ]
    }
   ],
   "source": [
    "# Iterate through columns with 'object' but not mixed\n",
    "def check_object_and_examples(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        col_type = infer_dtype(df[col])\n",
    "\n",
    "        if 'mixed' in col_type:\n",
    "            print(f\"Skipping '{col}' (has mixed types)\")\n",
    "            continue\n",
    "\n",
    "        example_value = df[col].dropna().iloc[0] if not df[col].dropna().empty else \"No data\"\n",
    "        print(f\"Column: {col}, Example: {example_value}\")\n",
    "\n",
    "check_object_and_examples(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:04.629614183Z",
     "start_time": "2025-06-06T20:09:04.311585820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Convert time columns to datetime with timezone awareness\n",
    "df['StartTime'] = pd.to_datetime(df['StartTime'], utc=True)\n",
    "df['EndTime'] = pd.to_datetime(df['EndTime'], utc=True)\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)  # Appears to have timezone info (+01:00)\n",
    "\n",
    "df['StartPort'] = df['StartPort'].astype('string').astype('category')\n",
    "df['EndPort'] = df['EndPort'].astype('string').astype('category')\n",
    "df['shiptype'] = df['shiptype'].astype('category')\n",
    "\n",
    "#NOTE discovered separately later\n",
    "df['Destination'] = df['Destination'].astype('string').astype('category')\n",
    "\n",
    "check_object_and_examples(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:08.888166243Z",
     "start_time": "2025-06-06T20:09:04.663539389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df.to_parquet(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T20:09:09.240901229Z",
     "start_time": "2025-06-06T20:09:08.892015415Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
